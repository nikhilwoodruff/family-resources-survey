{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "suited-nelson",
   "metadata": {},
   "source": [
    "# family-resources-survey\n",
    "\n",
    "This is a small Python package aiming to make processing data from the UK Family Resources Survey as easy as possible. This documentation outlines the basic usage principles and some examples. The package is designed to handle the conversion from TAB files to Pandas DataFrames, but by default uses MicroDataFrames, a modification of the DataFrame class which handles survey weighting behind the scenes and provides useful population-related functions.\n",
    "\n",
    "## Installation\n",
    "\n",
    "Install the package from the git repository, using pip:\n",
    "```console\n",
    "pip install git+https://github.com/nikhilwoodruff/family-resources-survey\n",
    "```\n",
    "\n",
    "## Initialising with Microdata\n",
    "\n",
    "The Family Resources Survey is classified as *safeguarded* on the UK Data Service (more restrictive than *open*, but less restrictive than *controlled*). This means you need to have an account with the UK Data Service to be able to request the microdata. Once you have, simply find the desired issue of the FRS, and download the TAB microdata (only TAB files are supported right now). Then, use the command:\n",
    "```console\n",
    "frs-data save --path [PATH_TO_ZIP_FILE] -- year [YEAR] --zipped\n",
    "```\n",
    "This will save the microdata in the package, and run any preprocessing necessary. The package will index the tables by person, benunit and household, and try to automatically parse the codebook (this works with the 2018 release, others have not been tested). The ```zipped``` argument just specifies that the folder is zipped and should be extracted - if you've already done this (and extracted to inside another folder), you can leave it out and point it to that folder instead (just make sure that the object the script is pointed to has the same structure as the zipped file). Then, from a Python environment, it's trivial to import the microdata in the right format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "chinese-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "from family_resources_survey import FRS\n",
    "\n",
    "frs = FRS(2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-corruption",
   "metadata": {},
   "source": [
    "This ```frs``` object has all the tables as properties (they'll be loaded when/if you access them), and a ```description``` dictionary if the codebook parsing was successful. The tables are stored as MicroDataFrames where they have the weights explicitly provided (that is, for tables 'adult', 'benunit', and 'househol'). If not, they're returned as normal DataFrames.\n",
    "\n",
    "## Relational Tools\n",
    "\n",
    "The FRS is a relational database - one person might have zero or more jobs, and these are linked using primary and foreign keys. This package has two top-level tools for doing things quickly that need to operate over multiple tables: ```consolidate``` and ```join```.\n",
    "\n",
    "### Consolidate\n",
    "\n",
    "Often a table can contain multiple entries for the same person - for example, a person can have more than one job. This can cause problems, so the ```consolidate``` function takes the table, a maximum number of occurrences that we want to distinguish $n$, a new column name to write the number of occurrences for each person, and optionally can set $n$ to its maximum from the data. For example, let's say in the jobs table (suppose it contains one variable called 'pay') that at most a person has 4 jobs. We can perform a few different operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "senior-chest",
   "metadata": {},
   "outputs": [],
   "source": [
    "from family_resources_survey import consolidate\n",
    "\n",
    "consolidate(table=frs.job, max_count=1, count_label=\"num_jobs\")    # 1\n",
    "consolidate(table=frs.job, max_count=2, count_label=\"num_jobs\")    # 2\n",
    "consolidate(table=frs.job, count_label=\"num_jobs\", count_all=True) # 3\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-lambda",
   "metadata": {},
   "source": [
    "1. Returns a dataframe with a row per person and the column \"PAY\", which is the PAY summed over all jobs for this person.\n",
    "2. Returns a dataframe with a row per person and the columns \"PAY_1\", \"PAY_other\", which is the PAY from the first job, and the PAY summed from others, respectively.\n",
    "3. Returns a dataframe with a row per person and the columns \"PAY_1\", \"PAY_2\", \"PAY_3\", \"PAY_4\", which is the PAY from each job, respectively. Equivalent to setting max_count to 4, but we don't need to figure out to do that beforehand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brazilian-chambers",
   "metadata": {},
   "source": [
    "## Join\n",
    "\n",
    "```join``` is simpler - it just recursively performs a left join on all the dataframes passed into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "equivalent-purse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from family_resources_survey import join\n",
    "\n",
    "join(frs.adult, consolidate(frs.job), consolidate(frs.mortgage))\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-jewel",
   "metadata": {},
   "source": [
    "Here, we've consolidated by summing up the amounts in JOB and MORTGAGE per person, and first joined JOB onto ADULT, then MORTGAGE onto the result of that.\n",
    "\n",
    "## Contact\n",
    "\n",
    "Feel free to contact with any questions. This package is purely a data processing tool - no adjustments are applied on the microdata."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
